# -*- coding: utf-8 -*-
"""HousingPrice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18KNYDaPpUqrynhXDM4snQHNQJUp_7a80

# Predicting Housing Prices
## CS 4210 - Professor Marin
#### Neil Patrick Reyes
#### Drake Fafard
#### Jason Ryan Jones
#### Andrew Sanford
#### Vu Nguyen

## Import libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import scale
from sklearn import preprocessing
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
from sklearn import metrics
from sklearn.inspection import permutation_importance
import math

"""## Step 1: Cleaning"""

# URL of the Training CSV file
train_url = "https://raw.githubusercontent.com/neilpreyes/ML_Data/main/train.csv"

# Read the CSV file into a DataFrame
df_train = pd.read_csv(train_url)
sum(df_train.duplicated())

# URL of the Test CSV file
test_url = "https://raw.githubusercontent.com/neilpreyes/ML_Data/main/test.csv"

# Read the CSV file into a DataFrame
df_test = pd.read_csv(test_url)
sum(df_test.duplicated())

# Display the DataFrame
df_train.head()

df_test.head()

"""##Step 2: Visualize the Data"""

import matplotlib.colors as mcolors
colors = list(mcolors.CSS4_COLORS.keys())[10:]
fig = plt.figure(figsize=(20,20))
for i, feature in enumerate(df_train.columns):
  f = fig.add_subplot(21, 4, i+1)
  df_train[feature].hist(bins = 20, ax = f, facecolor = colors[i])
  f.set_title(feature + " Histogram", color = colors[35])
fig.tight_layout()
plt.show()

plt.figure(figsize = (40, 32))

# Create a heatmap with rotated labels
heatmap = sns.heatmap(df_train.corr(), annot=True, fmt=".2f", cmap="coolwarm", linewidths=0.5, square=True)

# Rotate the labels for better readability
heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation=45, horizontalalignment='right')
heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0)

plt.show()

"""## Step 3: Drop unnecessary features"""

#In a heat map: 1 - positive correlation, -1 - negative correlation, 0 - no correlation
df_train = df_train.drop(columns=['Id', 'MSSubClass', 'OverallCond', 'BsmtFinSF2', 'LowQualFinSF', 'BsmtHalfBath', 'KitchenAbvGr', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold'])
#Remove same columns as training set
df_test = df_test.drop(columns=['Id', 'MSSubClass', 'OverallCond', 'BsmtFinSF2', 'LowQualFinSF', 'BsmtHalfBath', 'KitchenAbvGr', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold'])

"""## Step 4: Map The Data"""

#MAP DATA TO NUMBER VALUES
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()

"""
for column in df_train.columns:
    if df_train[column].dtype == 'O':  # Check if the data type is object (string)
        df_train[column] = label_encoder.fit_transform(df_train[column])
"""

# Define custom mapping for each categorical column
mapping = {
    'MSZoning': {'A': 0, 'C': 1, 'FV': 2, 'I': 3, 'RH': 4, 'RL': 5, 'RP': 6, 'RM': 7},
    'Street': {'Grvl': 1, 'Pave': 2},
    'Alley': {'Grvl': 1, 'Pave': 2, 'NA': 0},
    'LotShape': {'Reg': 3, 'IR1': 2, 'IR2': 1, 'IR3': 0},
    'LandContour': {'Lvl': 3, 'Bnk': 2, 'HLS': 1, 'Low': 0},
    'Utilities': {'AllPub': 3, 'NoSewr': 2, 'NoSeWa': 1, 'ELO': 0},
    'LotConfig': {'Inside': 4, 'Corner': 3, 'CulDSac': 2, 'FR2': 1, 'FR3': 0},
    'LandSlope': {'Gtl': 2, 'Mod': 1, 'Sev': 0},
    'Neighborhood': {'Blmngtn': 0, 'Blueste': 1, 'BrDale': 2, 'BrkSide': 3, 'ClearCr': 4, 'CollgCr': 5, 'Crawfor': 6, 'Edwards': 7, 'Gilbert': 8, 'IDOTRR': 9, 'MeadowV': 10, 'Mitchel': 11, 'Names': 12, 'NoRidge': 13, 'NPkVill': 14, 'NridgHt': 15, 'NWAmes': 16, 'OldTown': 17, 'SWISU': 18, 'Sawyer': 19, 'SawyerW': 20, 'Somerst': 21, 'StoneBr': 22, 'Timber': 23, 'Veenker': 24},
    'Condition1': {'Artery': 8, 'Feedr': 7, 'Norm': 6, 'RRNn': 5, 'RRAn': 4, 'PosN': 3, 'PosA': 2, 'RRNe': 1, 'RRAe': 0},
    'Condition2': {'Artery': 8, 'Feedr': 7, 'Norm': 6, 'RRNn': 5, 'RRAn': 4, 'PosN': 3, 'PosA': 2, 'RRNe': 1, 'RRAe': 0},
    'BldgType': {'1Fam': 4, '2FmCon': 3, 'Duplx': 2, 'TwnhsE': 1, 'TwnhsI': 0},
    'HouseStyle': {'1Story': 0, '1.5Fin': 2, '1.5Unf': 1, '2Story': 3, '2.5Fin': 5, '2.5Unf': 6, 'SFoyer': -1, 'SLvl': -1},
    'OverallQual': {10: 10, 9: 9, 8: 8, 7: 7, 6: 6, 5: 5, 4: 4, 3: 3, 2: 2, 1: 1},
    'RoofStyle': {'Flat': 0, 'Gable': 1, 'Gambrel': 2, 'Hip': 3, 'Mansard': 4, 'Shed': 5},

    'RoofMatl': {'ClyTile': 7, 'CompShg': 6, 'Membran': 5, 'Metal': 4, 'Roll': 3, 'Tar&Grv': 2,
             'WdShake': 1, 'WdShngl': 0},

    'Exterior1st': {'AsbShng': 16, 'AsphShn': 15, 'BrkComm': 14, 'BrkFace': 13, 'CBlock': 12, 'CemntBd': 11,
                'HdBoard': 10, 'ImStucc': 9, 'MetalSd': 8, 'Other': 7, 'Plywood': 6, 'PreCast': 5,
                'Stone': 4, 'Stucco': 3, 'VinylSd': 2, 'Wd Sdng': 1, 'WdShing': 0},

    'Exterior2nd': {'AsbShng': 16, 'AsphShn': 15, 'BrkComm': 14, 'BrkFace': 13, 'CBlock': 12, 'CemntBd': 11,
                'HdBoard': 10, 'ImStucc': 9, 'MetalSd': 8, 'Other': 7, 'Plywood': 6, 'PreCast': 5,
                'Stone': 4, 'Stucco': 3, 'VinylSd': 2, 'Wd Sdng': 1, 'WdShing': 0},

    'MasVnrType': {'BrkCmn': 4, 'BrkFace': 3, 'CBlock': 2, 'None': 1, 'Stone': 0},

    'ExterQual': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0},

    'ExterCond': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0},

    'Foundation': {'BrkTil': 4, 'CBlock': 3, 'PConc': 2, 'Slab': 1, 'Stone': 0, 'Wood': -1},

    'BsmtQual': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0},

    'BsmtCond': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0},

    'BsmtExposure': {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NA': 0},

    'BsmtFinType1': {'GLQ': 5, 'ALQ': 4, 'BLQ': 3, 'Rec': 2, 'LwQ': 1, 'Unf': 0, 'NA': -1},

    'BsmtFinType2': {'GLQ': 5, 'ALQ': 4, 'BLQ': 3, 'Rec': 2, 'LwQ': 1, 'Unf': 0, 'NA': -1},

    'Heating': {'Floor': 0, 'GasA': 1, 'GasW': 2, 'Grav': 3, 'OthW': 4, 'Wall': 5},

    'HeatingQC': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0},

    'CentralAir': {'N': 0, 'Y': 1},

    'Electrical': {'SBrkr': 3, 'FuseA': 2, 'FuseF': 1, 'FuseP': 0, 'Mix': -1},

    'KitchenQual': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0},

    'Functional': {'Typ': 7, 'Min1': 6, 'Min2': 5, 'Mod': 4, 'Maj1': 3, 'Maj2': 2, 'Sev': 1, 'Sal': 0},

    'FireplaceQu': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0, 'NA': -1},

    'GarageType': {'2Types': 6, 'Attchd': 5, 'Basment': 4, 'BuiltIn': 3, 'CarPort': 2, 'Detchd': 1, 'NA': 0},

    'GarageFinish': {'Fin': 2, 'RFn': 1, 'Unf': 0, 'NA': -1},

    'GarageQual': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0, 'NA': -1},

    'GarageCond': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0, 'NA': -1},

    'PavedDrive': {'Y': 2, 'P': 1, 'N': 0},

    'PoolQC': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'NA': 0},

    'Fence': {'GdPrv': 3, 'MnPrv': 2, 'GdWo': 1, 'MnWw': 0, 'NA': -1},

    'MiscFeature': {'Elev': 5, 'Gar2': 4, 'Othr': 3, 'Shed': 2, 'TenC': 1, 'NA': 0},

    'SaleType': {'WD': 9, 'CWD': 8, 'VWD': 7, 'New': 6, 'COD': 5, 'Con': 4, 'ConLw': 3, 'ConLI': 2, 'ConLD': 1, 'Oth': 0},

    'SaleCondition': {'Normal': 5, 'Abnorml': 4, 'AdjLand': 3, 'Alloca': 2, 'Family': 1, 'Partial': 0}
}

# Apply mapping to the DataFrame
for col, col_mapping in mapping.items():
    df_train[col] = df_train[col].map(col_mapping)

for col, col_mapping in mapping.items():
    df_test[col] = df_test[col].map(col_mapping)

plt.figure(figsize = (40, 32))

# Create a heatmap with rotated labels
heatmap = sns.heatmap(df_train.corr(), annot=True, fmt=".2f", cmap="coolwarm", linewidths=0.5, square=True)

# Rotate the labels for better readability
heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation=45, horizontalalignment='right')
heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0)

plt.show()

#In a heat map: 1 - positive correlation, -1 - negative correlation, 0 - no correlation
df_train = df_train.drop(columns=['MSZoning', 'LotShape', 'LandSlope', 'LotConfig', 'Condition1', 'Condition2', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'Foundation', 'BsmtFinType2', 'Heating', 'MiscFeature', 'SaleCondition',
                                   'SaleType'])
#Remove same columns as training set
df_test = df_test.drop(columns=['MSZoning', 'LotShape', 'LandSlope', 'LotConfig', 'Condition1', 'Condition2', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'Foundation', 'BsmtFinType2', 'Heating', 'MiscFeature', 'SaleCondition',
                                   'SaleType'])

plt.figure(figsize = (40, 32))

# Create a heatmap with rotated labels
heatmap = sns.heatmap(df_train.corr(), annot=True, fmt=".2f", cmap="coolwarm", linewidths=0.5, square=True)

# Rotate the labels for better readability
heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation=45, horizontalalignment='right')
heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0)

plt.show()

#Create X and Y Training
X_train = df_train.iloc[:, df_train.columns != 'SalePrice']
Y_train = df_train.iloc[:, df_train.columns == 'SalePrice']

#Create X Test (No Y because SalePrice is not a column)
X_test = df_test.copy()

X_train.head()

X_test.head()

"""## Step 5: Remove NaN From Data

## Step 6: Scale The Data
"""

X_train.fillna(X_train.mean(), inplace=True)
X_test.fillna(X_test.mean(), inplace=True)

#Scale Data using scaler to transform training set
scaler = preprocessing.StandardScaler().fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""## Step 7: Train Data

"""

# Necessary imports
from sklearn.model_selection import LeaveOneOut
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np
import math
import copy  # For deep copying the models

# Assuming X_train_scaled and Y_train are predefined and properly formatted

# Initialize LeaveOneOut and LinearRegression
loo = LeaveOneOut()
regressor = LinearRegression()

mse_scores = []
mae_scores = []

# Initialize the best model tracking variables
best_mse = float('inf')
best_rmse = float('inf')
best_mae = float('inf')
best_model = None

# Perform LOO cross-validation
for train_index, test_index in loo.split(X_train_scaled):
    X_train_loo, X_test_loo = X_train_scaled[train_index], X_train_scaled[test_index]
    y_train_loo, y_test_loo = Y_train.iloc[train_index], Y_train.iloc[test_index]

    # Fit the model
    regressor.fit(X_train_loo, y_train_loo)

    # Predict and calculate errors
    y_pred_loo = regressor.predict(X_test_loo)
    mse = mean_squared_error(y_test_loo, y_pred_loo)
    rmse = math.sqrt(mse)
    mae = mean_absolute_error(y_test_loo, y_pred_loo)

    mse_scores.append(mse)
    mae_scores.append(mae)

    # Update best model and metrics if current model is better
    if mse < best_mse:
        best_mse = mse
        best_rmse = rmse
        best_mae = mae
        best_model = copy.deepcopy(regressor)  # Deep copy of the model

# Calculate average errors
average_mse = np.mean(mse_scores)
average_mae = np.mean(mae_scores)
average_rmse = math.sqrt(average_mse)

# Output average errors and best errors
print("Average MSE using LOO CV:", average_mse)
print("Average RMSE using LOO CV:", average_rmse)
print("Average MAE using LOO CV:", average_mae)
print("Best MSE from LOO CV:", best_mse)
print("Best RMSE from LOO CV:", best_rmse)
print("Best MAE from LOO CV:", best_mae)

# Train the model on the entire training dataset
best_model = LinearRegression()
best_model.fit(X_train_scaled, Y_train)

# Predict the values using the trained model
train_predictions = best_model.predict(X_train_scaled)

# Calculate and output metrics for training data
train_mse = mean_squared_error(Y_train, train_predictions)
train_rmse = math.sqrt(train_mse)
train_mae = mean_absolute_error(Y_train, train_predictions)
print("Training MSE:", train_mse)
print("Training RMSE:", train_rmse)
print("Training MAE:", train_mae)

"""## Step 8: Evaluate the Model on the Test Dataset"""

# Predict the values on the test dataset
test_predictions = best_model.predict(X_test_scaled)
id_column = X_test.iloc[:, 0]

# If get the actual target values for the test set, uncomment and use the following lines:
# test_mse = mean_squared_error(Y_test, test_predictions)
# test_rmse = math.sqrt(test_mse)
# test_mae = mean_absolute_error(Y_test, test_predictions)
# print("Test MSE:", test_mse)
# print("Test RMSE:", test_rmse)
# print("Test MAE:", test_mae)

# Output the test predictions
# This assumes you want to output the predictions, similar to how you output the train predictions
predicted_df = pd.DataFrame({'ID': id_column, 'SalePrice': test_predictions.flatten()})

predicted_df.to_csv('/content/predicted_test_results.csv', index=False)

"""## Step 9: Run Regression

"""

# import itertools

# model = LinearRegression()

# # Store actual values

# # Predict the y values using the trained model
# predicted_values = model.predict(X_test_scaled)

# predicted_values_1D = []

# for number in predicted_values:
#   predicted_values_1D.append(number[0])

# print(predicted_values_1D)

# # Create an ID column starting from 1461
# id_column = np.arange(1461, 1461 + len(predicted_values))

# print(id_column)

# # Create a DataFrame for predicted values with the ID column
# predicted_df = pd.DataFrame({'ID': id_column, 'SalePrice': predicted_values_1D})

# # Merge the DataFrames on the ID column
# #result_df = pd.merge(actual_values, predicted_df, left_index=True, right_index=True)

# # Output the DataFrame to a CSV file
# predicted_df.to_csv('/content/predicted_vs_actual_with_id.csv', index=False)

# Predict the y values using the trained model
predicted_values = best_model.predict(X_test_scaled)

# Flatten the predicted values to 1D list for easier DataFrame creation
predicted_values_1D = predicted_values.flatten()

# Create an ID column starting from 1461 (assuming this is the starting ID for your test set)
id_column = np.arange(1461, 1461 + len(predicted_values))

# Create a DataFrame for predicted values with the ID column
predicted_df = pd.DataFrame({'ID': id_column, 'SalePrice': predicted_values_1D})

# Output the DataFrame to a CSV file
predicted_df.to_csv('/content/predicted_vs_actual_with_id.csv', index=False)

"""## Step 10 Conclusion"""